{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b7e5b7b",
   "metadata": {},
   "source": [
    "# AdaBoost Algorithm - Custom Implementation\n",
    "\n",
    "## Introduction\n",
    "\n",
    "**AdaBoost (Adaptive Boosting)** is one of the most successful ensemble techniques for improving the accuracy of machine learning models. It combines multiple \"weak learners\" to form a \"strong learner\" through a process of learning from the misclassified data points of the previous models. The core principle behind AdaBoost is to set the weights of classifiers and training data to ensure that subsequent classifiers focus more on the examples that previous classifiers misclassified.\n",
    "\n",
    "In this project, we will implement the AdaBoost algorithm using Python. We'll build the AdaBoost classifier from scratch, utilizing simple models (such as Decision Trees and Naive Bayes) as our weak learners. This hands-on approach will help us understand the fundamental mechanisms of AdaBoost, including weight updating and the role of error rates in shaping the sequential learning process.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "1. **Implement the AdaBoost Algorithm**: We will develop functions to create and manage weak learners, calculate their errors, update data weights, and combine their predictions into a final ensemble decision.\n",
    "   \n",
    "2. **Experiment with Different Weak Learners**: Our implementation will randomly select between using a Naive Bayes classifier and a Decision Tree (stump) for each iteration, exploring how different weak learners perform within the same AdaBoost framework.\n",
    "\n",
    "3. **Evaluate Performance**: The effectiveness of our ensemble model will be assessed using accuracy metrics. We will also visualize the performance improvements as the number of models in the ensemble increases.\n",
    "\n",
    "4. **Parameter Tuning and Validation**: Optional steps will include tuning parameters and validating the model using techniques like cross-validation to ensure robustness.\n",
    "\n",
    "## Dataset\n",
    "\n",
    "The dataset used in this project (`drugY.csv`) involves predicting a categorical target based on a mix of categorical and numerical features. We will preprocess the data by converting categorical variables into dummy/indicator variables, ensuring compatibility with our model training functions.\n",
    "\n",
    "## Structure of the Notebook\n",
    "\n",
    "The notebook is structured into several blocks:\n",
    "- **Setup**: Import necessary libraries and load the dataset.\n",
    "- **Data Preprocessing**: Prepare the data for modeling, including train-test splitting and dummy encoding.\n",
    "- **AdaBoost Implementation**: Define and implement the AdaBoost functions.\n",
    "- **Model Training**: Train the AdaBoost ensemble using our implementation.\n",
    "- **Evaluation**: Assess the model's performance and visualize results.\n",
    "- **Parameter Tuning and Cross-Validation**: Further refine the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed2f3954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b79c5f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>BP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Na</th>\n",
       "      <th>K</th>\n",
       "      <th>Drug</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>F</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>0.792535</td>\n",
       "      <td>0.031258</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47</td>\n",
       "      <td>M</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>0.739309</td>\n",
       "      <td>0.056468</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>M</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>0.697269</td>\n",
       "      <td>0.068944</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>F</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>0.563682</td>\n",
       "      <td>0.072289</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61</td>\n",
       "      <td>F</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>0.559294</td>\n",
       "      <td>0.030998</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Sex      BP Cholesterol        Na         K  Drug\n",
       "0   23   F    HIGH        HIGH  0.792535  0.031258     1\n",
       "1   47   M     LOW        HIGH  0.739309  0.056468     0\n",
       "2   47   M     LOW        HIGH  0.697269  0.068944     0\n",
       "3   28   F  NORMAL        HIGH  0.563682  0.072289     0\n",
       "4   61   F     LOW        HIGH  0.559294  0.030998     1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Loading and Preprocessing\n",
    "data = pd.read_csv('drugY.csv')\n",
    "\n",
    "# Preprocess data: Convert categorical variables using dummy encoding and split data\n",
    "X = pd.get_dummies(data.drop('Drug', axis=1))\n",
    "y = data['Drug']*2 - 1  # Assuming 'Drug' is the target and needs transformation\n",
    "\n",
    "# Split data into training and testing sets for validation purposes\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7021ac7b",
   "metadata": {},
   "source": [
    "## AdaBoost algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db58e0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(n):\n",
    "    \"\"\" Initialize the weights uniformly for all instances.\n",
    "        This ensures that initially, every instance contributes equally to the learning of the model.\n",
    "    \"\"\"\n",
    "    return np.ones(n) / n\n",
    "\n",
    "def train_weak_learner(X, y, sample_weights):\n",
    "    \"\"\" Train a weak learner. Randomly choose between Naive Bayes and Decision Tree.\n",
    "        Weak learners are simple classifiers which perform slightly better than random guessing.\n",
    "    \"\"\"\n",
    "    if random.choice(['NB', 'DT']) == 'NB':\n",
    "        learner = GaussianNB()  # Naive Bayes model\n",
    "    else:\n",
    "        learner = DecisionTreeClassifier(max_depth=1)  # Decision tree with depth of 1 (stump)\n",
    "    learner.fit(X, y, sample_weight=sample_weights)  # Fit the model with the sample weights\n",
    "    return learner\n",
    "\n",
    "def calculate_error(predictions, actual, weights):\n",
    "    \"\"\" Calculate the error of the weak learner weighted by the instance weights.\n",
    "        Error is calculated as the weighted average of incorrect predictions.\n",
    "    \"\"\"\n",
    "    is_incorrect = predictions != actual\n",
    "    weighted_errors = weights[is_incorrect]  # Weights corresponding to incorrect predictions\n",
    "    return weighted_errors.sum()  # Sum of weighted errors gives the total error\n",
    "\n",
    "def update_weights(weights, alpha, predictions, actual):\n",
    "    \"\"\" Update the instance weights based on the predictions.\n",
    "        Incorrectly classified instances are given higher weights.\n",
    "    \"\"\"\n",
    "    is_incorrect = predictions != actual\n",
    "    weights *= np.exp(alpha * is_incorrect)  # Increase weight for incorrectly classified instances\n",
    "    return weights / weights.sum()  # Normalize weights to sum to 1\n",
    "\n",
    "def ada_boost(X, y, M):\n",
    "    \"\"\" AdaBoost algorithm to create and combine weak learners.\n",
    "        It iteratively adds models to the ensemble, focusing on difficult instances by adjusting their weights.\n",
    "    \"\"\"\n",
    "    n = len(y)\n",
    "    weights = initialize_weights(n)  # Initialize uniform weights\n",
    "    models = []\n",
    "    alphas = []\n",
    "\n",
    "    for _ in range(M):\n",
    "        model = train_weak_learner(X, y, weights)\n",
    "        predictions = model.predict(X)\n",
    "        error = calculate_error(predictions, y, weights)\n",
    "        alpha = 0.5 * np.log((1 - error) / error)  # Calculate the weight of the model based on its accuracy\n",
    "        weights = update_weights(weights, alpha, predictions, y)  # Update instance weights for the next iteration\n",
    "\n",
    "        models.append(model)  # Save the trained model\n",
    "        alphas.append(alpha)  # Save the model weight\n",
    "\n",
    "    return models, alphas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910a9eb6",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a9b71da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of iterations\n",
    "M = 10\n",
    "models, alphas = ada_boost(X_train, y_train, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb4a3870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble accuracy: 0.925\n"
     ]
    }
   ],
   "source": [
    "def predict_ensemble(models, alphas, X):\n",
    "    \"\"\" Make predictions with the AdaBoost ensemble. \"\"\"\n",
    "    predictions = np.array([alpha * model.predict(X) for model, alpha in zip(models, alphas)])\n",
    "    return np.sign(predictions.sum(axis=0))\n",
    "\n",
    "# Evaluate model\n",
    "ensemble_predictions = predict_ensemble(models, alphas, X_test)\n",
    "print('Ensemble accuracy:', accuracy_score(y_test, ensemble_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "247cb5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': 3}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Parameter tuning using cross-validation could be performed here for the weak learners.\n",
    "# Example for Decision Tree depth tuning:\n",
    "param_grid = {'max_depth': [1, 2, 3, 4, 5]}\n",
    "model = DecisionTreeClassifier()\n",
    "cv_model = GridSearchCV(model, param_grid, cv=5)\n",
    "cv_model.fit(X_train, y_train)\n",
    "print('Best parameters:', cv_model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4559e5b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
